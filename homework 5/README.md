# Python

## Запуск
Выполнить `script_python.py`

### Флаги

`--file путь` - указать путь к логу (от корня репозитория)

`--json` - сохранить собранные данные в JSON

## Принцип работы
Запись осуществляется в `/tmp/parsed_log/by_python`.
Строки лога считываются в список `lines_log`, в процессе чего
разделяются по пробелу.
В процессе шагов ниже переменная `string_output` пополняется
необходимыми данными и в конце записывается в файл.

1) **Общее количество запросов**

   Вычисляется длина списка строк лога.


2) **Общее количество запросов по типу**

   Создаётся словарь с начальным значением 0 для любого ключа. 
   Значимая часть элемента №5 каждой строки лога используется, как ключ
   для словаря - значение увеличивается на 1. 
   В строку вывода записываются типы запросов и соответствующие им
   значения из словаря.


3) **Топ 10 самых частых запросов**

   Создаётся список из элементов №6 (`url`) каждой строки лога. 
   При помощи `collections.Counter` выявляется топ 10 самых частых.


4) **Топ 5 самых больших по размеру запросов, которые завершились
   клиентской ошибкой**

   Создаётся список из элементов №6, №8 (`статус_код`), №9 
   (`размер_запроса`) и №0 (`ip_адрес`) тех строк лога, у которых 
   элемент №8 начинается с "4". 
   Происходит сортировка по бывшему элементу №9 в обратном порядке.


5) **Топ 5 пользователей по количеству запросов, которые завершились
   серверной ошибкой**

   Создаётся список из элементов №0 тех строк лога, у которых элемент 
   №8 начинается с "5". 
   При помощи `collections.Counter` выявляется топ 5 самых частых.


# Bash

## Запуск
Выполнить `script_bash.sh путь_к_логу_от_корня_репозитория`

## Принцип работы
Запись осуществляется в `/tmp/parsed_log/by_bash`.
Вывод, полученный в процессе шагов ниже, записывается в файл.

1) **Общее количество запросов**

   При помощи `wc` вычисляется количество строк лога.


2) **Общее количество запросов по типу**

   `grep` получает тип запроса с каждой строки - ищется `начало_строки
   любые_символы "начало_захвата любые_символы захват_до_пробела`.
   `sort` сортирует это, тем самым помещая одинаковые запросы рядом.
   `uniq` унифицирует рядом расположенные одинаковые запросы, выводя
   число унифицированных запросов вместе с одним оставшимся.
   `awk` делает вывод с форматированием.


3) **Топ 10 самых частых запросов**
   
   `grep` получает `url` каждой строки лога - ищется `начало_строки
   любые_символы " любые_символы пробел началo_захвата любые_символы
   захват_до_пробела`.
   `sort` сортирует это.
   `uniq` унифицирует запросы.
   `sort` сортирует это в обратном порядке.
   `head` получает первые 10 запросов.
   `awk` делает вывод с форматированием.


4) **Топ 5 самых больших по размеру запросов, которые завершились
   клиентской ошибкой**

   `grep` получает каждую подходящую строку лога - ищется `начало_строки
   любые_символы " любые_символы " пробел 4`.
   `awk` дублирует размеры запросов перед строками.
   `sort` сортирует это в обратном порядке.
   `head` получает первые 5 запросов.
   `awk` делает вывод с форматированием.


5) **Топ 5 пользователей по количеству запросов, которые завершились
   серверной ошибкой**

   `grep` получает каждый подходящий `ip_адрес` - ищется `начало_строки
   любые_символы захват_до(пробел любые_символы " любые_символы " пробел
   5)`.
   `sort` сортирует это.
   `uniq` унифицирует запросы, выводя количество.
   `sort` сортирует это в обратном порядке.
   `head` получает первые 5 запросов.
   `awk` делает вывод с форматированием.